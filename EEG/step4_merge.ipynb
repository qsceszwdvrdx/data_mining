{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = ['f','m','p','s']\n",
    "order = ['before','test','after']\n",
    "aisle = ['aisle1','aisle2','aisle3','aisle4','aisle5']\n",
    "bands = ['alpha','beta','gamma','delta','theta']\n",
    "parts = ['part1','part2','part3','part4']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature merge >>>  all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before====================================\n",
      "id f: merging.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id m: merging.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id p: merging.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id s: merging.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test====================================\n",
      "id f: merging.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id m: merging.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id p: merging.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id s: merging.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after====================================\n",
      "id f: merging.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id m: merging.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id p: merging.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id s: merging.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:07<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "for o in order:\n",
    "    print(o+'====================================')\n",
    "    for x in id:\n",
    "        root = 'C:/Users/user/Desktop/eeg/feature/'+ o +'/'+ x +'/'\n",
    "        part1_paths = glob.glob(os.path.join(root,'first*.csv'))\n",
    "        part2_paths =  glob.glob(os.path.join(root,'second*.csv'))\n",
    "\n",
    "        print('id ' + x +': merging.....')\n",
    "        for p in tqdm(range(len(part1_paths))):\n",
    "            file_1st = pd.read_csv(part1_paths[p])\n",
    "            file_2nd = pd.read_csv(part2_paths[p])\n",
    "            file_merge = pd.concat((file_1st,file_2nd), axis='columns')\n",
    "            file_merge.to_csv('C:/Users/user/Desktop/eeg/feature/'+ o +'/all/'+ x +'_'+part1_paths[p][-37:],index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bands merge >>> bands all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for b in bands:\n",
    "#     print(b+'======================================================')\n",
    "#     for o in order:\n",
    "#         print(o+'====================================')\n",
    "#         for x in tqdm(id):\n",
    "#             # print(x+'==================')\n",
    "#             root = 'C:/Users/user/Desktop/eeg/bands_feature/'+ b +'/'+ o +'/'+ x +'/'\n",
    "#             part1_paths = glob.glob(os.path.join(root,'first*.csv'))\n",
    "#             part2_paths =  glob.glob(os.path.join(root,'second*.csv'))\n",
    "#             for p in range(len(part1_paths)):\n",
    "#                 df_first = pd.read_csv(part1_paths[p])\n",
    "#                 df_second = pd.read_csv(part2_paths[p])\n",
    "#                 df = pd.concat((df_first,df_second), axis=1)\n",
    "#                 df.to_csv('C:/Users/user/Desktop/eeg/bands_feature/'+ b +'/'+ o +'/all/'+ x +'_'+part1_paths[p][-37:],index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge raw_data and bands_raw_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bands_data_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before============================================\n",
      "f============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 1244.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 1249.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 1657.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 1656.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test============================================\n",
      "f============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 555.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 624.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 712.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 712.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after============================================\n",
      "f============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 1249.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 1249.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 1665.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 1665.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "for o in order: \n",
    "    print(o+'============================================')\n",
    "    for x in id:\n",
    "        print(x+'============================================')\n",
    "        paths = []\n",
    "        for b in tqdm(range(len(bands))): \n",
    "            # print(bands[b])\n",
    "            root = 'C:/Users/user/Desktop/eeg/bands_feature/'+ bands[b] +'/'+ o +'/all/'\n",
    "            files = os.listdir(root) # 8 * 4 id = 32 files\n",
    "            id_files = [a for a in files if a[0]==x]\n",
    "            for p in id_files:\n",
    "                paths.append(os.path.join(root,p))\n",
    "        # print(len(paths))\n",
    "        \n",
    "        grouped_dict = defaultdict(list)\n",
    "        for p in range(len(paths)):\n",
    "            if o == 'test':\n",
    "                grouped_dict[p%16].append(paths[p])\n",
    "            else:\n",
    "                grouped_dict[p%8].append(paths[p])\n",
    "        \n",
    "        # print(len(grouped_dict))\n",
    "        for g in range(len(grouped_dict)): # same file\n",
    "            each_file = []\n",
    "            for f in range(len(grouped_dict[g])): # same band\n",
    "                df = pd.read_csv(grouped_dict[g][f])\n",
    "                # if o == 'test':\n",
    "                #     df = df.drop(['id','light','music','before','after','date'],axis=1)\n",
    "                # else:\n",
    "                #     df = df.drop(['id','light','music','date'],axis=1)\n",
    "                new_columns = [col+'_'+bands[f]  for col in df.columns]\n",
    "                df = df.rename(columns=dict(zip(df.columns, new_columns)))\n",
    "                each_file.append(df)\n",
    "            df_file = pd.concat((each_file), axis=1)\n",
    "            df_file.to_csv('C:/Users/user/Desktop/eeg/bands_feature/order/'+ o +'/'+ x + '_' +grouped_dict[g][f][-37:],index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:06<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:12<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:06<00:00,  5.11it/s]\n"
     ]
    }
   ],
   "source": [
    "for o in order:\n",
    "    print(o+'============================================')\n",
    "    root1 = 'C:/Users/user/Desktop/eeg/feature/'+ o +'/all/'\n",
    "    paths1 = glob.glob(os.path.join(root1,'*.csv'))\n",
    "    root2 = 'C:/Users/user/Desktop/eeg/bands_feature/order/'+ o +'/'\n",
    "    paths2 = glob.glob(os.path.join(root2,'*.csv'))\n",
    "\n",
    "    n = []\n",
    "    for p in tqdm(range(len(paths1))):\n",
    "        df1 = pd.read_csv(paths1[p])\n",
    "        df2 = pd.read_csv(paths2[p])\n",
    "        df = pd.concat((df1,df2), axis=1)\n",
    "        n.append(df)\n",
    "    final = pd.concat((n))\n",
    "    final.to_csv('C:/Users/user/Desktop/eeg/all_'+ o +'_feature4.csv',index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
