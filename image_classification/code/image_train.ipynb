{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WbUpSKui-dDw","executionInfo":{"status":"ok","timestamp":1672637751955,"user_tz":-480,"elapsed":33356,"user":{"displayName":"謝誠閔","userId":"05924830952620661636"}},"outputId":"cfb6804a-0f27-4066-f2f5-1c1bfd6304d8"},"id":"WbUpSKui-dDw","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"id":"c0d1a062","metadata":{"id":"c0d1a062"},"outputs":[],"source":["import os\n","import math\n","import random\n","import zipfile\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","from keras.models import load_model\n","from tensorflow.keras import optimizers\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, GlobalMaxPooling2D\n","from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, Callback\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator\n","from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions"]},{"cell_type":"code","source":["with zipfile.ZipFile('/content/drive/MyDrive/碩二上/多媒體/data/pokemon/image.zip', 'r') as zf:\n","  zf.extractall('/content/image')\n","zf.close()"],"metadata":{"id":"JEDUkJ6L-o5K"},"id":"JEDUkJ6L-o5K","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"8cd8812b","metadata":{"id":"8cd8812b"},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold \n","df = pd.read_csv('/content/drive/MyDrive/碩二上/多媒體/data/pokemon/image.csv')\n","kf = StratifiedKFold(n_splits=5)\n","y = df['category']\n","\n","total_train = len(df)\n","total_validate = total_train / 5\n","\n","train_index_list , test_index_list = [],[]\n","for train_index , test_index in kf.split(df,y):\n","    train_index_list.append(train_index)\n","    test_index_list.append(test_index)"]},{"cell_type":"code","execution_count":null,"id":"5eaeda11","metadata":{"id":"5eaeda11"},"outputs":[],"source":["img_width, img_height = 180, 180\n","target_size = (img_width, img_height) \n","batch_size = 16\n","x_col, y_col = 'filename', 'category' \n","class_mode = 'categorical'\n","\n","train_datagen = ImageDataGenerator(rescale=1./255, # 正規化\n","                   rotation_range=10, # 隨機旋轉\n","                  #  shear_range=0.2, # 錯切\n","                  #  zoom_range=0.2, # 放大\n","                  #  horizontal_flip=True, # 水平翻轉\n","                  #  width_shift_range=0.1, # 左右移動\n","                  #  height_shift_range=0.1 # 上下移動\n","                  )\n","\n","valid_datagen = ImageDataGenerator(rescale=1./255)"]},{"cell_type":"code","execution_count":null,"id":"7a0f3b27","metadata":{"id":"7a0f3b27"},"outputs":[],"source":["def step_decay(epoch):      # epoch每增加10 學習率降一半\n","    initial_lrate = 0.001 \n","    drop = 0.5 \n","    epochs_drop = 10.0 \n","    lrate = initial_lrate * math.pow(drop, math.floor((epoch)/epochs_drop))\n","    return lrate\n","\n","lrate = LearningRateScheduler(step_decay)\n","earstop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5) "]},{"cell_type":"code","execution_count":null,"id":"1d23faa6","metadata":{"id":"1d23faa6"},"outputs":[],"source":["input_shape = (img_width, img_height, 3)\n","pre_trained_model = tf.keras.applications.resnet.ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n","\n","model = Sequential()\n","input_shape = (img_width, img_height, 3)\n","model.add(pre_trained_model)\n","model.add(Dropout(0.25))\n","model.add(GlobalMaxPooling2D())\n","model.add(Dense(256,activation='relu'))\n","model.add(Dropout(0.4))\n","model.add(Dense(128,activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(3,activation='softmax'))\n","model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"id":"a6fdf0a2","metadata":{"id":"a6fdf0a2"},"outputs":[],"source":["for i in range(5):\n","    train_df , validate_df = df.loc[train_index_list[i],:] , df.loc[test_index_list[i],:]\n","\n","    train_df['category'] = train_df['category'].astype(str)\n","    validate_df['category'] = validate_df['category'].astype(str)\n","    \n","    train_generator = train_datagen.flow_from_dataframe(train_df,                            \n","                               \"C:/Users/User/Desktop/data/image_train/\",                    \n","                               x_col=x_col, y_col=y_col,                                             \n","                               class_mode=class_mode,                            \n","                               target_size=target_size,                          \n","                               batch_size=batch_size)  \n","    \n","    valid_generator = valid_datagen.flow_from_dataframe(validate_df,                            \n","                               \"C:/Users/User/Desktop/data/image_train/\",                           \n","                               x_col=x_col, y_col=y_col,                                                                                   \n","                               class_mode=class_mode,                             \n","                               target_size=target_size,                            \n","                               batch_size=batch_size)\n","\n","    epochs = 15 \n","    history = model.fit(train_generator, \n","                        epochs=epochs, \n","                        validation_data=valid_generator,  \n","                        verbose=1,\n","                        callbacks=[lrate, earstop])\n","    \n","    model.save('C:/Users/User/Desktop/data/resnet50_64_' + str(i+1) + '.h5')"]},{"cell_type":"code","execution_count":null,"id":"498bd4c1","metadata":{"id":"498bd4c1"},"outputs":[],"source":["input_shape = (img_width, img_height, 3)\n","pre_trained_model = tf.keras.applications.resnet.ResNet101(include_top=False, weights='imagenet', input_shape=input_shape)\n","\n","model = Sequential()\n","input_shape = (img_width, img_height, 3)\n","model.add(pre_trained_model)\n","model.add(Dropout(0.25))\n","model.add(GlobalMaxPooling2D())\n","model.add(Dense(256,activation='relu'))\n","model.add(Dropout(0.4))\n","model.add(Dense(128,activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(3,activation='softmax'))\n","model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"id":"a43e76bf","metadata":{"id":"a43e76bf","outputId":"5e57c6df-09c6-4a28-c49a-f690ad982a53"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 719 validated image filenames belonging to 3 classes.\n","Found 180 validated image filenames belonging to 3 classes.\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","45/45 [==============================] - 474s 10s/step - loss: 3.2772 - accuracy: 0.6384 - val_loss: 5.5770 - val_accuracy: 0.3333 - lr: 0.0010\n","Epoch 2/15\n","45/45 [==============================] - 435s 10s/step - loss: 0.5533 - accuracy: 0.8915 - val_loss: 14.7281 - val_accuracy: 0.3333 - lr: 0.0010\n","Epoch 3/15\n","45/45 [==============================] - 436s 10s/step - loss: 0.4243 - accuracy: 0.9179 - val_loss: 4.3984 - val_accuracy: 0.3333 - lr: 0.0010\n","Epoch 4/15\n","45/45 [==============================] - 432s 10s/step - loss: 0.1633 - accuracy: 0.9611 - val_loss: 3.4803 - val_accuracy: 0.3500 - lr: 0.0010\n","Epoch 5/15\n","45/45 [==============================] - 450s 10s/step - loss: 0.2141 - accuracy: 0.9597 - val_loss: 4.8692 - val_accuracy: 0.3333 - lr: 0.0010\n","Epoch 6/15\n","45/45 [==============================] - 456s 10s/step - loss: 0.0961 - accuracy: 0.9764 - val_loss: 4.1674 - val_accuracy: 0.2611 - lr: 0.0010\n","Epoch 7/15\n","45/45 [==============================] - 420s 9s/step - loss: 0.0837 - accuracy: 0.9847 - val_loss: 2.9503 - val_accuracy: 0.3333 - lr: 0.0010\n","Epoch 8/15\n","45/45 [==============================] - 425s 9s/step - loss: 0.0493 - accuracy: 0.9889 - val_loss: 3.3685 - val_accuracy: 0.3333 - lr: 0.0010\n","Epoch 9/15\n","45/45 [==============================] - 409s 9s/step - loss: 0.0604 - accuracy: 0.9861 - val_loss: 2.9169 - val_accuracy: 0.3389 - lr: 0.0010\n","Epoch 10/15\n","45/45 [==============================] - 409s 9s/step - loss: 0.0614 - accuracy: 0.9861 - val_loss: 3.7862 - val_accuracy: 0.3333 - lr: 0.0010\n","Epoch 11/15\n","45/45 [==============================] - 410s 9s/step - loss: 0.0200 - accuracy: 0.9917 - val_loss: 3.9391 - val_accuracy: 0.3222 - lr: 5.0000e-04\n","Epoch 12/15\n","45/45 [==============================] - 409s 9s/step - loss: 0.0436 - accuracy: 0.9889 - val_loss: 4.3046 - val_accuracy: 0.3222 - lr: 5.0000e-04\n","Epoch 13/15\n","45/45 [==============================] - 409s 9s/step - loss: 0.0146 - accuracy: 0.9944 - val_loss: 4.4476 - val_accuracy: 0.3389 - lr: 5.0000e-04\n","Epoch 14/15\n","45/45 [==============================] - 410s 9s/step - loss: 0.0094 - accuracy: 0.9958 - val_loss: 3.5890 - val_accuracy: 0.4056 - lr: 5.0000e-04\n","Found 719 validated image filenames belonging to 3 classes.\n","Found 180 validated image filenames belonging to 3 classes.\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","45/45 [==============================] - 409s 9s/step - loss: 0.1205 - accuracy: 0.9861 - val_loss: 1.8438 - val_accuracy: 0.6000 - lr: 0.0010\n","Epoch 2/15\n","45/45 [==============================] - 410s 9s/step - loss: 0.0647 - accuracy: 0.9861 - val_loss: 0.5552 - val_accuracy: 0.8444 - lr: 0.0010\n","Epoch 3/15\n","45/45 [==============================] - 410s 9s/step - loss: 0.0247 - accuracy: 0.9903 - val_loss: 0.3047 - val_accuracy: 0.8944 - lr: 0.0010\n","Epoch 4/15\n","45/45 [==============================] - 411s 9s/step - loss: 0.0289 - accuracy: 0.9930 - val_loss: 0.1147 - val_accuracy: 0.9722 - lr: 0.0010\n","Epoch 5/15\n","45/45 [==============================] - 417s 9s/step - loss: 0.0416 - accuracy: 0.9930 - val_loss: 0.1190 - val_accuracy: 0.9722 - lr: 0.0010\n","Epoch 6/15\n","45/45 [==============================] - 418s 9s/step - loss: 0.0373 - accuracy: 0.9944 - val_loss: 0.0194 - val_accuracy: 0.9889 - lr: 0.0010\n","Epoch 7/15\n","45/45 [==============================] - 435s 10s/step - loss: 0.0257 - accuracy: 0.9917 - val_loss: 0.0050 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 8/15\n","45/45 [==============================] - 432s 10s/step - loss: 0.0572 - accuracy: 0.9889 - val_loss: 2.6388e-04 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 9/15\n","45/45 [==============================] - 446s 10s/step - loss: 0.0193 - accuracy: 0.9903 - val_loss: 4.3644e-06 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 10/15\n","45/45 [==============================] - 461s 10s/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 9.9341e-08 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 11/15\n","45/45 [==============================] - 460s 10s/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 4.5697e-08 - val_accuracy: 1.0000 - lr: 5.0000e-04\n","Epoch 12/15\n","45/45 [==============================] - 456s 10s/step - loss: 0.0165 - accuracy: 0.9972 - val_loss: 4.3048e-08 - val_accuracy: 1.0000 - lr: 5.0000e-04\n","Epoch 13/15\n","45/45 [==============================] - 441s 10s/step - loss: 0.0099 - accuracy: 0.9958 - val_loss: 5.0995e-08 - val_accuracy: 1.0000 - lr: 5.0000e-04\n","Epoch 14/15\n","45/45 [==============================] - 439s 10s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4504e-08 - val_accuracy: 1.0000 - lr: 5.0000e-04\n","Epoch 15/15\n","45/45 [==============================] - 414s 9s/step - loss: 0.0023 - accuracy: 0.9972 - val_loss: 2.3180e-08 - val_accuracy: 1.0000 - lr: 5.0000e-04\n","Found 719 validated image filenames belonging to 3 classes.\n","Found 180 validated image filenames belonging to 3 classes.\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","45/45 [==============================] - 441s 10s/step - loss: 0.0197 - accuracy: 0.9944 - val_loss: 1.7550e-07 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 2/15\n","45/45 [==============================] - 447s 10s/step - loss: 0.0069 - accuracy: 0.9958 - val_loss: 9.2056e-08 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 3/15\n","45/45 [==============================] - 453s 10s/step - loss: 0.0398 - accuracy: 0.9944 - val_loss: 4.6359e-08 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 4/15\n","45/45 [==============================] - 447s 10s/step - loss: 0.0108 - accuracy: 0.9972 - val_loss: 1.7881e-08 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 5/15\n","45/45 [==============================] - 434s 10s/step - loss: 0.0588 - accuracy: 0.9944 - val_loss: 1.3079e-06 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 6/15\n","45/45 [==============================] - 519s 12s/step - loss: 0.0174 - accuracy: 0.9972 - val_loss: 1.0317e-06 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 7/15\n","45/45 [==============================] - 500s 11s/step - loss: 0.0169 - accuracy: 0.9986 - val_loss: 5.6357e-07 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 8/15\n","45/45 [==============================] - 476s 11s/step - loss: 0.0101 - accuracy: 0.9958 - val_loss: 2.8782e-06 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 9/15\n","45/45 [==============================] - 476s 11s/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 5.1047e-05 - val_accuracy: 1.0000 - lr: 0.0010\n","Found 720 validated image filenames belonging to 3 classes.\n","Found 179 validated image filenames belonging to 3 classes.\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","45/45 [==============================] - 471s 10s/step - loss: 0.0026 - accuracy: 0.9986 - val_loss: 1.4851e-07 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 2/15\n","45/45 [==============================] - 433s 10s/step - loss: 0.0399 - accuracy: 0.9917 - val_loss: 8.3175e-07 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 3/15\n","45/45 [==============================] - 448s 10s/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 3.0501e-07 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 4/15\n","45/45 [==============================] - 433s 10s/step - loss: 0.0101 - accuracy: 0.9972 - val_loss: 7.4589e-08 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 5/15\n","45/45 [==============================] - 435s 10s/step - loss: 0.0180 - accuracy: 0.9931 - val_loss: 2.8637e-08 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 6/15\n","45/45 [==============================] - 480s 11s/step - loss: 0.0049 - accuracy: 0.9958 - val_loss: 3.7960e-08 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 7/15\n","45/45 [==============================] - 457s 10s/step - loss: 0.0132 - accuracy: 0.9972 - val_loss: 7.7919e-08 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 8/15\n","45/45 [==============================] - 523s 12s/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 1.1721e-07 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 9/15\n","45/45 [==============================] - 527s 12s/step - loss: 5.6206e-04 - accuracy: 1.0000 - val_loss: 1.0589e-07 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 10/15\n","45/45 [==============================] - 543s 12s/step - loss: 8.1741e-04 - accuracy: 1.0000 - val_loss: 1.2587e-07 - val_accuracy: 1.0000 - lr: 0.0010\n","Found 719 validated image filenames belonging to 3 classes.\n","Found 180 validated image filenames belonging to 3 classes.\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","45/45 [==============================] - 516s 11s/step - loss: 0.0249 - accuracy: 0.9958 - val_loss: 3.5895e-07 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 2/15\n","45/45 [==============================] - 495s 11s/step - loss: 0.0033 - accuracy: 0.9986 - val_loss: 5.1258e-07 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 3/15\n","45/45 [==============================] - 524s 12s/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 8.9400e-07 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 4/15\n","45/45 [==============================] - 503s 11s/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 7.7611e-06 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 5/15\n","45/45 [==============================] - 522s 12s/step - loss: 0.0034 - accuracy: 0.9986 - val_loss: 8.7906e-06 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 6/15\n","45/45 [==============================] - 507s 11s/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 1.8404e-05 - val_accuracy: 1.0000 - lr: 0.0010\n"]}],"source":["for i in range(5):\n","    train_df , validate_df = df.loc[train_index_list[i],:] , df.loc[test_index_list[i],:]\n","\n","    train_df['category'] = train_df['category'].astype(str)\n","    validate_df['category'] = validate_df['category'].astype(str)\n","    \n","    train_generator = train_datagen.flow_from_dataframe(train_df,                            \n","                               \"C:/Users/User/Desktop/data/image_train/\",                    \n","                               x_col=x_col, y_col=y_col,                                             \n","                               class_mode=class_mode,                            \n","                               target_size=target_size,                          \n","                               batch_size=batch_size)\n","    \n","    valid_generator = valid_datagen.flow_from_dataframe(validate_df,                            \n","                               \"C:/Users/User/Desktop/data/image_train/\",                           \n","                               x_col=x_col, y_col=y_col,                                                                                   \n","                               class_mode=class_mode,                             \n","                               target_size=target_size,                            \n","                               batch_size=batch_size)\n","\n","    epochs = 15 \n","    history = model.fit(train_generator, \n","               epochs=epochs, \n","#                steps_per_epoch=total_train//batch_size, \n","               validation_data=valid_generator, \n","#                validation_steps=total_validate//batch_size, \n","               verbose=1,\n","               callbacks=[lrate, earstop])\n","    \n","    model.save('C:/Users/User/Desktop/data/resnet101_' + str(i+1) + '.h5')"]},{"cell_type":"code","execution_count":null,"id":"719979eb","metadata":{"id":"719979eb"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"7c42a7da","metadata":{"id":"7c42a7da"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"2bc3155c","metadata":{"id":"2bc3155c"},"outputs":[],"source":["input_shape = (img_width, img_height, 3)\n","pre_trained_model = tf.keras.applications.resnet.ResNet152(include_top=False, weights='imagenet', input_shape=input_shape)\n","\n","model = Sequential()\n","input_shape = (img_width, img_height, 3)\n","model.add(pre_trained_model)\n","model.add(Dropout(0.25))\n","model.add(GlobalMaxPooling2D())\n","model.add(Dense(256,activation='relu'))\n","model.add(Dropout(0.4))\n","model.add(Dense(128,activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(3,activation='softmax'))\n","model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"id":"f9db2b64","metadata":{"id":"f9db2b64","outputId":"7b0f23b3-c28f-4a85-a44e-07662cdb29c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 719 validated image filenames belonging to 3 classes.\n","Found 180 validated image filenames belonging to 3 classes.\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","45/45 [==============================] - 698s 14s/step - loss: 2.7470 - accuracy: 0.6648 - val_loss: 4.3409 - val_accuracy: 0.3333 - lr: 0.0010\n","Epoch 2/15\n","45/45 [==============================] - 621s 14s/step - loss: 0.6473 - accuracy: 0.8734 - val_loss: 2.4342 - val_accuracy: 0.3333 - lr: 0.0010\n","Epoch 3/15\n","45/45 [==============================] - 613s 14s/step - loss: 0.2343 - accuracy: 0.9444 - val_loss: 1.7889 - val_accuracy: 0.3333 - lr: 0.0010\n","Epoch 4/15\n","45/45 [==============================] - 646s 14s/step - loss: 0.1505 - accuracy: 0.9652 - val_loss: 1.7165 - val_accuracy: 0.3278 - lr: 0.0010\n","Epoch 5/15\n","45/45 [==============================] - 651s 14s/step - loss: 0.0646 - accuracy: 0.9833 - val_loss: 2.0598 - val_accuracy: 0.3111 - lr: 0.0010\n","Epoch 6/15\n","45/45 [==============================] - 655s 15s/step - loss: 0.0923 - accuracy: 0.9764 - val_loss: 2.5895 - val_accuracy: 0.3389 - lr: 0.0010\n","Epoch 7/15\n","45/45 [==============================] - 647s 14s/step - loss: 0.1307 - accuracy: 0.9736 - val_loss: 3.0052 - val_accuracy: 0.3333 - lr: 0.0010\n","Epoch 8/15\n","45/45 [==============================] - 648s 14s/step - loss: 0.1085 - accuracy: 0.9805 - val_loss: 2.9143 - val_accuracy: 0.3444 - lr: 0.0010\n","Epoch 9/15\n","45/45 [==============================] - 635s 14s/step - loss: 0.0512 - accuracy: 0.9861 - val_loss: 3.0296 - val_accuracy: 0.3500 - lr: 0.0010\n","Found 719 validated image filenames belonging to 3 classes.\n","Found 180 validated image filenames belonging to 3 classes.\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","45/45 [==============================] - 619s 14s/step - loss: 0.0727 - accuracy: 0.9805 - val_loss: 3.1368 - val_accuracy: 0.3556 - lr: 0.0010\n","Epoch 2/15\n","45/45 [==============================] - 650s 14s/step - loss: 0.0705 - accuracy: 0.9833 - val_loss: 2.8187 - val_accuracy: 0.3833 - lr: 0.0010\n","Epoch 3/15\n","45/45 [==============================] - 647s 14s/step - loss: 0.0430 - accuracy: 0.9917 - val_loss: 3.4750 - val_accuracy: 0.3278 - lr: 0.0010\n","Epoch 4/15\n","45/45 [==============================] - 628s 14s/step - loss: 0.0744 - accuracy: 0.9875 - val_loss: 4.6802 - val_accuracy: 0.3333 - lr: 0.0010\n","Epoch 5/15\n","45/45 [==============================] - 588s 13s/step - loss: 0.0181 - accuracy: 0.9930 - val_loss: 4.5394 - val_accuracy: 0.3500 - lr: 0.0010\n","Epoch 6/15\n","45/45 [==============================] - 602s 13s/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 2.5167 - val_accuracy: 0.5333 - lr: 0.0010\n","Epoch 7/15\n","45/45 [==============================] - 590s 13s/step - loss: 0.0305 - accuracy: 0.9917 - val_loss: 2.2670 - val_accuracy: 0.5778 - lr: 0.0010\n","Epoch 8/15\n","45/45 [==============================] - 613s 14s/step - loss: 0.0523 - accuracy: 0.9861 - val_loss: 1.0256 - val_accuracy: 0.7944 - lr: 0.0010\n","Epoch 9/15\n","45/45 [==============================] - 604s 13s/step - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.4297 - val_accuracy: 0.9111 - lr: 0.0010\n","Epoch 10/15\n","45/45 [==============================] - 636s 14s/step - loss: 0.0251 - accuracy: 0.9917 - val_loss: 0.1536 - val_accuracy: 0.9778 - lr: 0.0010\n","Epoch 11/15\n","45/45 [==============================] - 591s 13s/step - loss: 0.0633 - accuracy: 0.9889 - val_loss: 0.0828 - val_accuracy: 0.9944 - lr: 5.0000e-04\n","Epoch 12/15\n","45/45 [==============================] - 586s 13s/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0026 - val_accuracy: 1.0000 - lr: 5.0000e-04\n","Epoch 13/15\n","45/45 [==============================] - 587s 13s/step - loss: 0.0316 - accuracy: 0.9944 - val_loss: 2.8035e-04 - val_accuracy: 1.0000 - lr: 5.0000e-04\n","Epoch 14/15\n","45/45 [==============================] - 587s 13s/step - loss: 0.0158 - accuracy: 0.9930 - val_loss: 3.4536e-06 - val_accuracy: 1.0000 - lr: 5.0000e-04\n","Epoch 15/15\n","45/45 [==============================] - 588s 13s/step - loss: 0.0061 - accuracy: 0.9972 - val_loss: 9.6360e-07 - val_accuracy: 1.0000 - lr: 5.0000e-04\n","Found 719 validated image filenames belonging to 3 classes.\n","Found 180 validated image filenames belonging to 3 classes.\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","45/45 [==============================] - 585s 13s/step - loss: 0.0350 - accuracy: 0.9917 - val_loss: 0.2045 - val_accuracy: 0.9778 - lr: 0.0010\n","Epoch 2/15\n","45/45 [==============================] - 591s 13s/step - loss: 0.0030 - accuracy: 0.9972 - val_loss: 0.2021 - val_accuracy: 0.9778 - lr: 0.0010\n","Epoch 3/15\n","45/45 [==============================] - 588s 13s/step - loss: 0.0487 - accuracy: 0.9917 - val_loss: 0.3275 - val_accuracy: 0.9667 - lr: 0.0010\n","Epoch 4/15\n","45/45 [==============================] - 587s 13s/step - loss: 0.0109 - accuracy: 0.9958 - val_loss: 0.3404 - val_accuracy: 0.9611 - lr: 0.0010\n","Epoch 5/15\n","45/45 [==============================] - 589s 13s/step - loss: 0.0071 - accuracy: 0.9958 - val_loss: 0.6323 - val_accuracy: 0.9556 - lr: 0.0010\n","Epoch 6/15\n","45/45 [==============================] - 588s 13s/step - loss: 0.0254 - accuracy: 0.9930 - val_loss: 0.7551 - val_accuracy: 0.9556 - lr: 0.0010\n","Epoch 7/15\n","45/45 [==============================] - 588s 13s/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.8697 - val_accuracy: 0.9556 - lr: 0.0010\n","Found 720 validated image filenames belonging to 3 classes.\n","Found 179 validated image filenames belonging to 3 classes.\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","45/45 [==============================] - 591s 13s/step - loss: 0.0211 - accuracy: 0.9958 - val_loss: 1.0664 - val_accuracy: 0.9665 - lr: 0.0010\n","Epoch 2/15\n","45/45 [==============================] - 590s 13s/step - loss: 0.0465 - accuracy: 0.9931 - val_loss: 1.0559 - val_accuracy: 0.9665 - lr: 0.0010\n","Epoch 3/15\n","45/45 [==============================] - 588s 13s/step - loss: 0.0014 - accuracy: 0.9986 - val_loss: 0.9464 - val_accuracy: 0.9665 - lr: 0.0010\n","Epoch 4/15\n","45/45 [==============================] - 588s 13s/step - loss: 0.0043 - accuracy: 0.9972 - val_loss: 0.8609 - val_accuracy: 0.9721 - lr: 0.0010\n","Epoch 5/15\n","45/45 [==============================] - 586s 13s/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.6393 - val_accuracy: 0.9832 - lr: 0.0010\n","Epoch 6/15\n","45/45 [==============================] - 589s 13s/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.5872 - val_accuracy: 0.9832 - lr: 0.0010\n","Epoch 7/15\n","45/45 [==============================] - 600s 13s/step - loss: 0.0017 - accuracy: 0.9986 - val_loss: 0.5712 - val_accuracy: 0.9832 - lr: 0.0010\n","Epoch 8/15\n","45/45 [==============================] - 642s 14s/step - loss: 0.0145 - accuracy: 0.9972 - val_loss: 0.7259 - val_accuracy: 0.9832 - lr: 0.0010\n","Epoch 9/15\n","45/45 [==============================] - 619s 14s/step - loss: 0.0183 - accuracy: 0.9986 - val_loss: 0.6791 - val_accuracy: 0.9832 - lr: 0.0010\n","Epoch 10/15\n","45/45 [==============================] - 590s 13s/step - loss: 0.0138 - accuracy: 0.9986 - val_loss: 0.6894 - val_accuracy: 0.9832 - lr: 0.0010\n","Epoch 11/15\n","45/45 [==============================] - 602s 13s/step - loss: 0.0168 - accuracy: 0.9958 - val_loss: 0.6676 - val_accuracy: 0.9832 - lr: 5.0000e-04\n","Epoch 12/15\n","45/45 [==============================] - 646s 14s/step - loss: 0.0044 - accuracy: 0.9972 - val_loss: 0.7220 - val_accuracy: 0.9832 - lr: 5.0000e-04\n","Found 719 validated image filenames belonging to 3 classes.\n","Found 180 validated image filenames belonging to 3 classes.\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","45/45 [==============================] - 702s 16s/step - loss: 0.0054 - accuracy: 0.9972 - val_loss: 5.0264e-07 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 2/15\n","45/45 [==============================] - 696s 16s/step - loss: 0.0029 - accuracy: 0.9986 - val_loss: 6.4902e-08 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 3/15\n","45/45 [==============================] - 697s 15s/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 6.2916e-08 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 4/15\n","19/45 [===========>..................] - ETA: 6:35 - loss: 0.0016 - accuracy: 1.0000"]}],"source":["for i in range(5):\n","    train_df , validate_df = df.loc[train_index_list[i],:] , df.loc[test_index_list[i],:]\n","\n","    train_df['category'] = train_df['category'].astype(str)\n","    validate_df['category'] = validate_df['category'].astype(str)\n","    \n","    train_generator = train_datagen.flow_from_dataframe(train_df,                            \n","                               \"C:/Users/User/Desktop/data/image_train/\",                    \n","                               x_col=x_col, y_col=y_col,                                             \n","                               class_mode=class_mode,                            \n","                               target_size=target_size,                          \n","                               batch_size=batch_size)\n","\n","     \n","    valid_generator = valid_datagen.flow_from_dataframe(validate_df,                            \n","                               \"C:/Users/User/Desktop/data/image_train/\",                           \n","                               x_col=x_col, y_col=y_col,                                                                                   \n","                               class_mode=class_mode,                             \n","                               target_size=target_size,                            \n","                               batch_size=batch_size)\n","\n","    epochs = 15 \n","    history = model.fit(train_generator, \n","               epochs=epochs, \n","#                steps_per_epoch=total_train//batch_size, \n","               validation_data=valid_generator, \n","#                validation_steps=total_validate//batch_size, \n","               verbose=1,\n","               callbacks=[lrate, earstop])\n","    \n","    model.save('C:/Users/User/Desktop/data/resnet152_' + str(i+1) + '.h5')"]},{"cell_type":"code","execution_count":null,"id":"8293cd50","metadata":{"id":"8293cd50"},"outputs":[],"source":[]},{"cell_type":"code","source":[],"metadata":{"id":"mrynD5tt_D8g"},"id":"mrynD5tt_D8g","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m0M81X5A_ETv","executionInfo":{"status":"ok","timestamp":1672637876252,"user_tz":-480,"elapsed":10228,"user":{"displayName":"謝誠閔","userId":"05924830952620661636"}},"outputId":"01c8dbbd-5127-4b28-b711-eec532ede60f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5\n","234698864/234698864 [==============================] - 2s 0us/step\n"]}],"source":["input_shape = (img_width, img_height, 3)\n","pre_trained_model = tf.keras.applications.resnet.ResNet152(include_top=False, weights='imagenet', input_shape=input_shape)\n","\n","model = Sequential()\n","input_shape = (img_width, img_height, 3)\n","model.add(pre_trained_model)\n","model.add(Dropout(0.25))\n","model.add(GlobalMaxPooling2D())\n","model.add(Dense(256,activation='relu'))\n","model.add(Dropout(0.4))\n","model.add(Dense(128,activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(3,activation='softmax'))\n","model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])"],"id":"m0M81X5A_ETv"},{"cell_type":"code","execution_count":null,"metadata":{"outputId":"de92cdc8-2e42-457c-b28c-32a97ac501e2","colab":{"base_uri":"https://localhost:8080/"},"id":"KDmHwBfl_ETw","executionInfo":{"status":"ok","timestamp":1672644997791,"user_tz":-480,"elapsed":7020670,"user":{"displayName":"謝誠閔","userId":"05924830952620661636"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 720 validated image filenames belonging to 3 classes.\n","Found 180 validated image filenames belonging to 3 classes.\n","Epoch 1/15\n","45/45 [==============================] - 1174s 26s/step - loss: 2.8441 - accuracy: 0.6278 - val_loss: 1.0478 - val_accuracy: 0.4833 - lr: 0.0010\n","Epoch 2/15\n","45/45 [==============================] - 1173s 26s/step - loss: 0.5624 - accuracy: 0.8792 - val_loss: 1.2479 - val_accuracy: 0.3667 - lr: 0.0010\n","Epoch 3/15\n","45/45 [==============================] - 1125s 25s/step - loss: 0.2473 - accuracy: 0.9361 - val_loss: 1.4574 - val_accuracy: 0.3389 - lr: 0.0010\n","Epoch 4/15\n","45/45 [==============================] - 1171s 26s/step - loss: 0.1307 - accuracy: 0.9708 - val_loss: 1.4697 - val_accuracy: 0.2611 - lr: 0.0010\n","Epoch 5/15\n","45/45 [==============================] - 1122s 25s/step - loss: 0.0944 - accuracy: 0.9694 - val_loss: 2.1754 - val_accuracy: 0.3333 - lr: 0.0010\n","Epoch 6/15\n","45/45 [==============================] - 1124s 25s/step - loss: 0.0898 - accuracy: 0.9750 - val_loss: 1.6669 - val_accuracy: 0.2389 - lr: 0.0010\n"]}],"source":["train_df , validate_df = df.loc[train_index_list[4],:] , df.loc[test_index_list[4],:]\n","\n","train_df['category'] = train_df['category'].astype(str)\n","validate_df['category'] = validate_df['category'].astype(str)\n","\n","train_generator = train_datagen.flow_from_dataframe(train_df,                            \n","                            \"/content/image/\",                    \n","                            x_col=x_col, y_col=y_col,                                             \n","                            class_mode=class_mode,                            \n","                            target_size=target_size,                          \n","                            batch_size=batch_size)\n","\n","  \n","valid_generator = valid_datagen.flow_from_dataframe(validate_df,                            \n","                            \"/content/image/\",                           \n","                            x_col=x_col, y_col=y_col,                                                                                   \n","                            class_mode=class_mode,                             \n","                            target_size=target_size,                            \n","                            batch_size=batch_size)\n","\n","epochs = 15 \n","history = model.fit(train_generator, \n","            epochs=epochs, \n","#                steps_per_epoch=total_train//batch_size, \n","            validation_data=valid_generator, \n","#                validation_steps=total_validate//batch_size, \n","            verbose=1,\n","            callbacks=[lrate, earstop])\n","\n","model.save('resnet152_5.h5')"],"id":"KDmHwBfl_ETw"},{"cell_type":"code","source":[],"metadata":{"id":"OQTMIikQ0nOH"},"id":"OQTMIikQ0nOH","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}